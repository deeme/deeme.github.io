<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title>Softmax - 标签 - DeemBear's Blog</title><link>https://deembear.top/tags/softmax/</link><description>Softmax - 标签 - DeemBear's Blog</description><generator>Hugo -- gohugo.io</generator><language>zh-CN</language><managingEditor>github.io@gmail.com (DeemBear)</managingEditor><webMaster>github.io@gmail.com (DeemBear)</webMaster><copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright><lastBuildDate>Fri, 20 Apr 2018 13:21:00 +0000</lastBuildDate><atom:link href="https://deembear.top/tags/softmax/" rel="self" type="application/rss+xml"/><item><title>Softmax 梯度下降优化</title><link>https://deembear.top/posts/research/softmax/</link><pubDate>Fri, 20 Apr 2018 13:21:00 +0000</pubDate><author>DeemBear</author><guid>https://deembear.top/posts/research/softmax/</guid><description>softmax函数简介： softmax函数是用来处理多分类的一种软性分类器，它输出的是每个类别的概率值。数据集特征矩阵为X其维度为D+1 x N</description></item></channel></rss>